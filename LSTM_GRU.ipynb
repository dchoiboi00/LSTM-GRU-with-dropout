{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23091,"status":"ok","timestamp":1727298007120,"user":{"displayName":"Yoo Choi","userId":"13482404619390770087"},"user_tz":240},"id":"WyK5h4iU6V9O","outputId":"29e451ba-b7d0-48bd-e887-07d06cbe9d66"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wandb\n","  Downloading wandb-0.18.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Collecting docker-pycreds>=0.4.0 (from wandb)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n","Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n","  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n","Collecting sentry-sdk>=1.0.0 (from wandb)\n","  Downloading sentry_sdk-2.14.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting setproctitle (from wandb)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n","  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n","  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n","Downloading wandb-0.18.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sentry_sdk-2.14.0-py2.py3-none-any.whl (311 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.4/311.4 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n","Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.14.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.18.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}],"source":["!pip install wandb\n","\n","!wandb login 9172fb113e07d174f618e9042047cc5c4adacc0f"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43242,"status":"ok","timestamp":1727298053594,"user":{"displayName":"Yoo Choi","userId":"13482404619390770087"},"user_tz":240},"id":"635B0VpqeaV0","outputId":"accaa1f8-b117-47a9-f1df-37ab5844d98f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import wandb\n","\n","# Mount files\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":229,"status":"ok","timestamp":1727298066064,"user":{"displayName":"Yoo Choi","userId":"13482404619390770087"},"user_tz":240},"id":"DTHSbOEIeibJ","outputId":"356d2d43-553a-46a5-c978-473f8605bae8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")"]},{"cell_type":"markdown","metadata":{"id":"XRf3z5CrCwiy"},"source":["# Data processing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2430,"status":"ok","timestamp":1727298069992,"user":{"displayName":"Yoo Choi","userId":"13482404619390770087"},"user_tz":240},"id":"Et4vfwgVek2a","outputId":"10f60605-c7ba-47c6-aad1-5c97c3f637c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train set shape: (929588,)\n","Validation set shape: (73759,)\n","Test set shape: (82429,)\n","Vocabulary size: 10000\n","[ 237  807  950 1325 1476 1691 3773 3920 4067 4380 4731 4922 5569 5732\n"," 5876 7091 7175 7366 7769 8203]\n","[8301 8478 8819 9658   43 6605   44   45 9965 6172 9838 4833 9012 1040\n","  609   48 6033 2631 6074   45]\n"]}],"source":["def data_init():\n","    with open(\"/content/drive/MyDrive/Colab Notebooks/data/ptb.train.txt\") as f:\n","        train = f.read().strip().replace('\\n', '<eos>').split()\n","    with open(\"/content/drive/MyDrive/Colab Notebooks/data/ptb.valid.txt\") as f:\n","        val = f.read().strip().replace('\\n', '<eos>').split()\n","    with open(\"/content/drive/MyDrive/Colab Notebooks/data/ptb.test.txt\") as f:\n","        test = f.read().strip().replace('\\n', '<eos>').split()\n","\n","    words = sorted(set(train))\n","    word2idx = {word: idx for idx, word in enumerate(words)}\n","    trn = [word2idx[w] for w in train]\n","    vld = [word2idx[w] if w in word2idx else word2idx['<unk>'] for w in val]\n","    tst = [word2idx[w] if w in word2idx else word2idx['<unk>'] for w in test]\n","\n","    return np.array(trn), np.array(vld), np.array(tst), len(words)\n","\n","train_set, val_set, test_set, vocab_size = data_init()\n","\n","print(\"Train set shape:\", train_set.shape)\n","print(\"Validation set shape:\", val_set.shape)\n","print(\"Test set shape:\", test_set.shape)\n","print(\"Vocabulary size:\", vocab_size)\n","print(train_set[:20])\n","print(train_set[20:40])\n","\n","# print(len(train_text), train_text[:10])\n","# print(len(valid_text), valid_text[:10])\n","# print(len(test_text), test_text[:10])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VkdQgSpE3B6m"},"outputs":[],"source":["# Batch data preparation\n","def minibatch(data, batch_size, seq_length):\n","    data = torch.tensor(data, dtype=torch.int64)\n","    num_batches = data.size(0) // batch_size\n","    data = data[:num_batches * batch_size].view(batch_size, -1)\n","\n","    dataset = []\n","    for i in range(0, data.size(1) - seq_length+1, seq_length):\n","        x = data[:, i:i + seq_length].transpose(1, 0)\n","        y = data[:, i+1:i+seq_length+1].transpose(1, 0)\n","        dataset.append((x, y))\n","    return dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":188,"status":"ok","timestamp":1727298073024,"user":{"displayName":"Yoo Choi","userId":"13482404619390770087"},"user_tz":240},"id":"WtSkAiVx3oYL","outputId":"95dee255-f116-4850-dcbf-f60be8d54313"},"outputs":[{"output_type":"stream","name":"stdout","text":["2323\n","184\n","206\n","torch.Size([20, 20])\n","torch.Size([20, 20])\n","tensor([[ 237, 9010,   45,  424,  657, 5133,   43, 9846, 4769, 8215, 6237, 2863,\n","          873, 7829,  424,   45, 7877,  406, 5442,   95],\n","        [ 807, 9928, 8093, 9805, 5086, 9012, 1097, 9012, 8713, 9961, 5234,   43,\n","         5782,   43,   44,   45, 5825, 6142, 1965, 6237],\n","        [ 950, 8304, 6142, 6378, 4470, 2764, 9888,   44,  609,   43, 9119, 1573,\n","         2602, 9119, 9869,  424,   44, 2362, 5799, 3352],\n","        [1325, 5232, 4770,   43, 6400, 8307, 7875, 9012, 9590, 3756,   48, 2096,\n","           43, 8860,  345,  270, 9012,  812, 6142, 2343],\n","        [1476,   48, 1800, 9010,  889, 9055, 9034, 3908, 7298, 1551, 4039,  413,\n","         5825, 9012, 9010, 6185, 2947,  555, 4619,    3],\n","        [1691, 1406, 8582, 5531, 6142, 5755,  373, 9846,  424, 4028, 9012,   44,\n","         7728, 6919, 5531,  536, 6142, 9842, 1717, 6920],\n","        [3773, 9474, 3659, 3957, 1283,  280, 3543, 9012, 6532, 6257, 3972, 1315,\n","         1768, 5993, 3659,   45,   44, 9119, 9705, 4470],\n","        [3920, 9869, 2897, 2124, 6965,  373, 4764,   44, 1868, 7806, 1342,  994,\n","          148, 6326, 7322,   45,   43, 3800, 3179, 9012],\n","        [4067, 2362, 6142,  873, 3876, 4017,   44,   43,  424, 7824, 3098, 3563,\n","          609, 4155, 5098,   43, 9869,  424,  657, 9668],\n","        [4380, 9010,   44, 5417, 1291, 8304, 9010, 5825, 9024, 9751, 9012, 4748,\n","           48, 7008, 2121, 4764, 6063, 9012,   73, 6142],\n","        [4731, 4764, 2498, 1678, 8583, 7198, 1452, 3079, 8002, 4764, 7843, 7977,\n","           44, 8056,  424, 9705, 9034, 6870,   45, 9012],\n","        [4922, 9928,    9, 9119,  543,   44, 5985,  424, 9020, 4144, 3628, 4403,\n","         3263,   48,  963, 2884,    8, 1180,  987,   44],\n","        [5569,   44,   45, 2265,   48, 4758, 4748, 5825,  657, 5347, 6142, 9012,\n","         5825,   44, 7064, 9054,   44,  311, 9889, 6167],\n","        [5732, 7820, 8093, 7871, 3681,   44,  493, 9051,   48,   48, 7544, 6573,\n","         6573, 9661, 7407, 4181, 2713, 9928,    1, 8435],\n","        [5876, 6237, 6296, 8132, 6142, 9696, 1878, 2843, 4353,  971,  424, 9966,\n","         4144, 7878,   43, 9010,   43,  873,   45,   43],\n","        [7091,   48,   43, 2121, 6961, 6142, 6185, 4470,   44, 3659, 7321, 1342,\n","           48, 9119, 4764, 9012, 2350, 9842, 5667, 5177],\n","        [7175, 1406, 5156, 4165, 9195, 4555, 5825, 2602,   43, 2041, 9012,  873,\n","           44, 9304, 4212, 5900, 9881, 9119, 5027, 9059],\n","        [7366,    9, 5901, 7824, 4729,   43, 4279,   44, 9012, 6142, 2254, 9504,\n","           44, 9119, 9119, 3568, 7646, 6448, 9958, 6142],\n","        [7769,   63,   48,   43, 3819, 1279,    9, 4470, 3946, 1707, 2423, 9119,\n","           43, 7389, 4902, 5079, 4477,   43,   43, 7833],\n","        [8203, 9119,  800, 5783, 2031, 9048, 6920, 9012, 7202, 1204,   43, 5378,\n","         2884, 4470, 6275, 9012, 5286, 5825, 1135,  900]])\n","tensor([[ 807, 9928, 8093, 9805, 5086, 9012, 1097, 9012, 8713, 9961, 5234,   43,\n","         5782,   43,   44,   45, 5825, 6142, 1965, 6237],\n","        [ 950, 8304, 6142, 6378, 4470, 2764, 9888,   44,  609,   43, 9119, 1573,\n","         2602, 9119, 9869,  424,   44, 2362, 5799, 3352],\n","        [1325, 5232, 4770,   43, 6400, 8307, 7875, 9012, 9590, 3756,   48, 2096,\n","           43, 8860,  345,  270, 9012,  812, 6142, 2343],\n","        [1476,   48, 1800, 9010,  889, 9055, 9034, 3908, 7298, 1551, 4039,  413,\n","         5825, 9012, 9010, 6185, 2947,  555, 4619,    3],\n","        [1691, 1406, 8582, 5531, 6142, 5755,  373, 9846,  424, 4028, 9012,   44,\n","         7728, 6919, 5531,  536, 6142, 9842, 1717, 6920],\n","        [3773, 9474, 3659, 3957, 1283,  280, 3543, 9012, 6532, 6257, 3972, 1315,\n","         1768, 5993, 3659,   45,   44, 9119, 9705, 4470],\n","        [3920, 9869, 2897, 2124, 6965,  373, 4764,   44, 1868, 7806, 1342,  994,\n","          148, 6326, 7322,   45,   43, 3800, 3179, 9012],\n","        [4067, 2362, 6142,  873, 3876, 4017,   44,   43,  424, 7824, 3098, 3563,\n","          609, 4155, 5098,   43, 9869,  424,  657, 9668],\n","        [4380, 9010,   44, 5417, 1291, 8304, 9010, 5825, 9024, 9751, 9012, 4748,\n","           48, 7008, 2121, 4764, 6063, 9012,   73, 6142],\n","        [4731, 4764, 2498, 1678, 8583, 7198, 1452, 3079, 8002, 4764, 7843, 7977,\n","           44, 8056,  424, 9705, 9034, 6870,   45, 9012],\n","        [4922, 9928,    9, 9119,  543,   44, 5985,  424, 9020, 4144, 3628, 4403,\n","         3263,   48,  963, 2884,    8, 1180,  987,   44],\n","        [5569,   44,   45, 2265,   48, 4758, 4748, 5825,  657, 5347, 6142, 9012,\n","         5825,   44, 7064, 9054,   44,  311, 9889, 6167],\n","        [5732, 7820, 8093, 7871, 3681,   44,  493, 9051,   48,   48, 7544, 6573,\n","         6573, 9661, 7407, 4181, 2713, 9928,    1, 8435],\n","        [5876, 6237, 6296, 8132, 6142, 9696, 1878, 2843, 4353,  971,  424, 9966,\n","         4144, 7878,   43, 9010,   43,  873,   45,   43],\n","        [7091,   48,   43, 2121, 6961, 6142, 6185, 4470,   44, 3659, 7321, 1342,\n","           48, 9119, 4764, 9012, 2350, 9842, 5667, 5177],\n","        [7175, 1406, 5156, 4165, 9195, 4555, 5825, 2602,   43, 2041, 9012,  873,\n","           44, 9304, 4212, 5900, 9881, 9119, 5027, 9059],\n","        [7366,    9, 5901, 7824, 4729,   43, 4279,   44, 9012, 6142, 2254, 9504,\n","           44, 9119, 9119, 3568, 7646, 6448, 9958, 6142],\n","        [7769,   63,   48,   43, 3819, 1279,    9, 4470, 3946, 1707, 2423, 9119,\n","           43, 7389, 4902, 5079, 4477,   43,   43, 7833],\n","        [8203, 9119,  800, 5783, 2031, 9048, 6920, 9012, 7202, 1204,   43, 5378,\n","         2884, 4470, 6275, 9012, 5286, 5825, 1135,  900],\n","        [8301, 1829, 4283, 6943,   43,   44,  609, 8687, 3659, 6667, 6803, 4770,\n","         9100, 7827, 9426,   44, 4770, 8572, 5347, 9020]])\n","*********\n"]}],"source":["#Testing minibatch\n","batch_size = 20\n","seq_length = 20\n","\n","train_batch = minibatch(train_set, batch_size, seq_length)\n","valid_batch = minibatch(val_set, batch_size, seq_length)\n","test_batch = minibatch(test_set, batch_size, seq_length)\n","\n","print(len(train_batch))\n","print(len(valid_batch))\n","print(len(test_batch))\n","\n","print(train_batch[0][0].shape)\n","print(train_batch[0][1].shape)\n","print(train_batch[0][0])\n","print(train_batch[0][1])\n","print(\"*********\")\n","\n","# for i, (x, y) in enumerate(valid_batch):\n","#     print(f\"Batch {i}: x shape: {x.shape}, y shape: {y.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"yo05XGyPFW1j"},"source":["# Defining our models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7OoDrJTRLYlI"},"outputs":[],"source":["class Model(nn.Module):\n","    def __init__(self, vocab_size, hidden_size, num_layers, dropout, rnn_type='LSTM'):\n","        super(Model, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.rnn_type = rnn_type\n","\n","        # Embedding layer to map input tokens to vectors\n","        self.embedding = nn.Embedding(vocab_size, hidden_size)\n","\n","        # RNN layer (either LSTM or GRU based on user choice)\n","        if rnn_type == 'LSTM':\n","            self.rnn = nn.LSTM(hidden_size, hidden_size, num_layers, dropout=dropout)\n","        elif rnn_type == 'GRU':\n","            self.rnn = nn.GRU(hidden_size, hidden_size, num_layers, dropout=dropout)\n","\n","        # Dropout layer to prevent overfitting\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        # Linear layer to map from hidden state to vocabulary size (for logits)\n","        self.fc = nn.Linear(hidden_size, vocab_size)\n","\n","        self.init_parameters()\n","\n","    # Initialize parameters to U(-0.1, 0.1)\n","    def init_parameters(self):\n","        for param in self.parameters():\n","            nn.init.uniform_(param, -0.1, 0.1)\n","\n","    # Forward pass: directly from paper\n","    def forward(self, x, states):\n","        x = self.dropout(self.embedding(x))  # Embedding input, then dropout\n","        x, states = self.rnn(x, states)  # Pass through RNN (LSTM or GRU)\n","        x = self.dropout(x)  # Apply dropout after rnn again\n","        x = self.fc(x)  # Final fully connected layer to get logits\n","        return x, states\n","\n","    # Initialize hidden (and cell) states\n","    def state_init(self, batch_size):\n","        if self.rnn_type == 'LSTM':\n","            # h0 = torch.randn(self.num_layers, batch_size, self.hidden_size).to(device)\n","            # c0 = torch.randn(self.num_layers, batch_size, self.hidden_size).to(device)\n","            h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n","            c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n","\n","            # h0 = torch.nn.init.xavier_uniform_(torch.empty(self.num_layers, batch_size, self.hidden_size)).to(device)\n","            # c0 = torch.nn.init.xavier_uniform_(torch.empty(self.num_layers, batch_size, self.hidden_size)).to(device)\n","\n","            return (h0, c0)\n","        else:  # GRU has only one hidden state\n","            h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n","            # h0 = torch.randn(self.num_layers, batch_size, self.hidden_size).to(device)\n","            # h0 = torch.nn.init.xavier_uniform_(torch.empty(self.num_layers, batch_size, self.hidden_size)).to(device)\n","\n","            return h0\n","\n","    # Detach hidden states (to avoid backpropagating through entire sequence)\n","    def detach(self, states):\n","        if isinstance(states, tuple):  # LSTM states\n","            return (states[0].detach(), states[1].detach())\n","        else:  # GRU state\n","            return states.detach()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uts8wucZIiN_"},"outputs":[],"source":["# Cross-entropy loss function\n","def cross_entropy_loss(scores, y):\n","    criterion = nn.CrossEntropyLoss()\n","    scores = scores.reshape(-1, scores.size(2))\n","    y = y.reshape(-1)\n","    loss = criterion(scores, y)\n","    return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0cZgojuXF0mq"},"outputs":[],"source":["# Perplexity calculation\n","def perplexity(data, model, batch_size):\n","    with torch.no_grad():\n","        losses = []\n","        states = model.state_init(batch_size)\n","        for x, y in data:\n","            x = x.to(device)\n","            y = y.to(device)\n","            scores, states = model(x, states)\n","            loss = cross_entropy_loss(scores, y)\n","            losses.append(loss.item())\n","    return np.exp(np.mean(losses))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ee_U0ygyCjA1"},"outputs":[],"source":["import timeit\n","\n","def train(data, path, model, epochs, initial_learning_rate, max_grad_norm, epoch_threshold, lr_decay, step_size=6, gamma=1.0/1.65, dropout=False):\n","    wandb.init(\n","        project=\"dl-ex2\",\n","        name=f'{model.rnn_type}_lr_{initial_learning_rate}_dropout_{model.dropout.p}',\n","        config={\n","        \"learning_rate\": initial_learning_rate,\n","        \"architecture\": model.rnn_type,\n","        \"hidden_size\": model.hidden_size,\n","        \"layer_num\": model.num_layers,\n","        \"epochs\": epochs,\n","        \"dropout\": model.dropout.p,\n","        \"batch_size\": batch_size,\n","        \"seq_length\": seq_length,\n","        \"max_grad_norm\": max_grad_norm\n","        }\n","    )\n","\n","    trn, vld, tst = data\n","    tic = timeit.default_timer()\n","    optimizer = optim.SGD(model.parameters(), lr=initial_learning_rate)\n","    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","    best_val_loss = float('inf')\n","    best_model = None\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        states = model.state_init(batch_size)\n","        total_loss = 0.0\n","        total_words = 0\n","\n","        for i, (x, y) in enumerate(trn):\n","            x = x.to(device)\n","            y = y.to(device)\n","\n","            states = model.detach(states)\n","            optimizer.zero_grad()\n","\n","            # Forward pass\n","            scores, states = model(x, states)\n","\n","            # Loss and Backpropagation\n","            loss = cross_entropy_loss(scores, y)\n","            loss.backward()\n","\n","            # Gradient clipping\n","            nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n","            optimizer.step()\n","\n","            total_loss += loss.item()\n","            total_words += y.numel()\n","            # Print 10 times per batch\n","            if i % (len(trn)//10) == 0:\n","                toc = timeit.default_timer()\n","                print(\"batch no = {:d} / {:d}, \".format(i, len(trn)) +\n","                      \"avg train loss per word this batch = {:.3f}, \".format(loss.item()) +\n","                      \"words per second = {:d}, \".format(round(total_words/(toc-tic))) +\n","                      \"lr = {:.3f}, \".format(optimizer.param_groups[0]['lr']) +\n","                      \"since beginning = {:d} mins, \".format(round((toc-tic)/60)))\n","\n","        avg_train_loss = total_loss / len(trn)\n","        train_perp = perplexity(trn, model, batch_size)\n","\n","        # Validation and Test perplexity\n","        model.eval()\n","        val_perp = perplexity(vld, model, batch_size)\n","        test_perp = perplexity(tst, model, batch_size)\n","        print(f\"Epoch {epoch + 1}: Start Learning Rate: {initial_learning_rate}, Dropout: {model.dropout.p}\")\n","        print(f\"Epoch {epoch + 1}: Train Loss: {avg_train_loss:.3f}\")\n","        print(f\"Epoch {epoch + 1}: Train Perplexity: {train_perp:.3f}\")\n","        print(f\"Epoch {epoch + 1}: Validation Perplexity: {val_perp:.3f}\")\n","        print(f\"Epoch {epoch + 1}: Test Perplexity: {test_perp:.3f}\")\n","\n","        # Wandb Plotting\n","        wandb.log({\"Train Perplexity\": train_perp, \"Validation Perplexity\": val_perp, \"Test Perplexity\": test_perp, \"epoch\": epoch, \"learning_rate\": optimizer.param_groups[0]['lr'],\"dropout\": model.dropout.p })\n","\n","        # Custom scheduler from paper -> Used only for LSTM with no dropout\n","        # Define \"epoch_threshold\" and \"lr_decay\" in arguments\n","        if model.rnn_type == 'LSTM' and dropout == False:\n","          if (epoch+1) >= epoch_threshold:\n","            for param_group in optimizer.param_groups:\n","                param_group['lr'] *= lr_decay  # Decay learning rate\n","\n","        # Step decay -> Used for (1) GRU no dropout, (2) LSTM with dropout, (3) GRU with dropout\n","        # Define \"step_size\" and \"gamma\" in arguments\n","        else:\n","          scheduler.step()\n","\n","        # Save the best model\n","        if val_perp < best_val_loss:\n","            print(f\"Saw better model at Epoch {epoch+1}\")\n","            best_val_loss = val_perp\n","            best_model = {k: v.clone() for k, v in model.state_dict().items()}\n","\n","    # Test set perplexity\n","    model.load_state_dict(best_model)\n","    test_perp = perplexity(tst, model, batch_size)\n","    print(f\"Test Set Perplexity: {test_perp:.3f} Model: {model.rnn_type} Dropout: {model.dropout.p} Hidden_size: {model.hidden_size}\")\n","\n","    torch.save(model, path)\n","    print(\"Training complete. Best model saved.\")\n"]},{"cell_type":"markdown","metadata":{"id":"E3WxWyHKFaH7"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zraSpyK8g1su"},"outputs":[],"source":["# Hyperparameters\n","batch_size = 20\n","seq_length = 20\n","hidden_size = 200\n","layer_num = 2\n","max_grad_norm = 5\n","\n","epoch_threshold = 7\n","lr_decay = 0.5\n","\n","# Initialize datasets\n","trn, vld, tst, vocab_size = data_init()\n","\n","trn = minibatch(trn, batch_size, seq_length)\n","vld = minibatch(vld, batch_size, seq_length)\n","tst = minibatch(tst, batch_size, seq_length)\n","\n","def run_experiments_no_dropout():\n","\n","    dropout = 0.0\n","    total_epochs = 15\n","\n","    step_size = 5\n","    gamma = 0.5\n","\n","\n","    for rnn_type in ['LSTM', 'GRU']:\n","        model = Model(vocab_size, hidden_size, layer_num, dropout, rnn_type=rnn_type).to(device)\n","        learning_rate = 2.0 if rnn_type=='LSTM' else 1.0\n","        path = f'/content/drive/MyDrive/Colab Notebooks/model/best_model_{model.rnn_type}_{learning_rate}_{model.dropout.p}.pth'\n","        train((trn, vld, tst), path, model, total_epochs, learning_rate, max_grad_norm, epoch_threshold, lr_decay, step_size, gamma, dropout=False)\n","\n","def run_experiments_with_dropout():\n","\n","    total_epochs = 25\n","    step_size = 6\n","\n","    for dropout in [0.25]:\n","      for rnn_type in ['LSTM', 'GRU']:\n","          model = Model(vocab_size, hidden_size, layer_num, dropout, rnn_type=rnn_type).to(device)\n","          learning_rate = 4.0 if rnn_type=='LSTM' else 2.0\n","          gamma = 1.0/1.65 if rnn_type == 'GRU' else 1.0/1.15\n","          step_size = 15 if rnn_type=='LSTM' else 6\n","          path = f'/content/drive/MyDrive/Colab Notebooks/model/best_model_{model.rnn_type}_{learning_rate}_{model.dropout.p}.pth'\n","          train((trn, vld, tst), path, model, total_epochs, learning_rate, max_grad_norm, epoch_threshold, lr_decay, step_size, gamma, dropout=True)\n","\n","# Call the function to run experiments\n","run_experiments_with_dropout()\n","run_experiments_no_dropout()"]},{"cell_type":"markdown","metadata":{"id":"EOQBsbysN5jN"},"source":["# Table"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":517},"id":"7ks-fBzgt80_","outputId":"616bc8c0-e3b3-4600-9e52-c31e0fe83c50"},"outputs":[{"data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"4d6d6a62-8eff-45a0-828d-5e802f707149\" class=\"plotly-graph-div\" style=\"height:500px; width:750px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4d6d6a62-8eff-45a0-828d-5e802f707149\")) {                    Plotly.newPlot(                        \"4d6d6a62-8eff-45a0-828d-5e802f707149\",                        [{\"cells\":{\"align\":\"left\",\"fill\":{\"color\":\"lavender\"},\"values\":[[\"LSTM No Dropout\",\"GRU No Dropout\",\"LSTM 25% Dropout\",\"GRU 25% Dropout\"],[72.49,67.35,67.97,59.98],[123.75,124.4,102.66,104.49],[119.82,119.98,99.08,100.88]]},\"header\":{\"align\":\"left\",\"fill\":{\"color\":\"coral\"},\"values\":[\"Model\",\"Training Perplexity\",\"Validation Perplexity\",\"Test Perplexity\"]},\"type\":\"table\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Perplexities of Various Models\"},\"height\":500,\"width\":750},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('4d6d6a62-8eff-45a0-828d-5e802f707149');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{},"output_type":"display_data"}],"source":["import pandas as pd\n","import plotly.graph_objects as go\n","\n","# Perplexity values are from WandB runs history\n","data = {\n","    'Model': ['LSTM No Dropout', 'GRU No Dropout', 'LSTM 25% Dropout', 'GRU 25% Dropout'],\n","    'Training Perplexity': [72.49, 67.35, 67.97, 59.98],\n","    'Validation Perplexity': [123.75, 124.40, 102.66, 104.49],\n","    'Test Perplexity': [119.82, 119.98, 99.08, 100.88]\n","}\n","\n","# Display table\n","df = pd.DataFrame(data)\n","\n","fig = go.Figure(data=[go.Table(\n","    header=dict(values=list(df.columns),\n","                fill_color='coral',\n","                align='left'),\n","    cells=dict(values=[df[col] for col in df.columns],\n","               fill_color='lavender',\n","               align='left'))\n","])\n","\n","fig.update_layout(\n","    title=\"Perplexities of Various Models\",\n","    height=500,\n","    width=750\n",")\n","\n","fig.show()"]},{"cell_type":"code","source":["model = torch.load('/content/drive/MyDrive/Colab Notebooks/model/best_model_LSTM_2.0_0.0.pth')\n","model.eval()\n","test_perp = perplexity(tst, model, batch_size)\n","test_perp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yP4wdnPVnESq","executionInfo":{"status":"ok","timestamp":1727292168231,"user_tz":240,"elapsed":608,"user":{"displayName":"Dahwi Kim","userId":"03544334411230229649"}},"outputId":"83621350-e514-49ae-c7bf-2e887a4ffcd1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-26-3a752606d0c7>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model = torch.load('/content/drive/MyDrive/Colab Notebooks/model/best_model_LSTM_2.0_0.0.pth')\n"]},{"output_type":"execute_result","data":{"text/plain":["123.50955553789018"]},"metadata":{},"execution_count":26}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}